mod audit;
mod auth;
mod cache;
mod config;
mod error;
mod event_listener;
mod http;
mod metrics;
mod models;
mod notify;
mod rpc;
mod s3;
mod search;
mod storage;
mod sync;
mod transfer;
mod version;
mod webdav;

use config::Config;
use error::Result;
use event_listener::EventListener;
use notify::EventNotifier;
use rpc::FileServiceImpl;
use sha2::Digest;
use silent::prelude::*;
use std::net::SocketAddr;
use std::sync::Arc;
use storage::StorageManager;
use sync::crdt::SyncManager;
use tonic::transport::Server as TonicServer;
use tracing::{Level, error, info};
use tracing_subscriber as logger;
use version::{VersionConfig, VersionManager};

#[tokio::main]
async fn main() -> Result<()> {
    // åˆå§‹åŒ–æ—¥å¿—
    logger::fmt().with_max_level(Level::INFO).init();

    info!("Silent-NAS æœåŠ¡å™¨å¯åŠ¨ä¸­...");

    // åŠ è½½é…ç½®
    let config = Config::load();
    info!("é…ç½®åŠ è½½å®Œæˆ: {:?}", config);

    // åˆå§‹åŒ–å­˜å‚¨ç®¡ç†å™¨
    let storage = StorageManager::new(config.storage.root_path.clone(), config.storage.chunk_size);
    storage.init().await?;

    // å°è¯•è¿æ¥ NATSï¼ˆå¯é€‰ï¼Œå•èŠ‚ç‚¹æ¨¡å¼ä¸‹å¯ä¸è¿æ¥ï¼‰
    let notifier =
        EventNotifier::try_connect(&config.nats.url, config.nats.topic_prefix.clone()).await;
    if notifier.is_some() {
        info!("âœ… NATS å·²è¿æ¥ - å¤šèŠ‚ç‚¹æ¨¡å¼å¯ç”¨");
    } else {
        info!("â„¹ï¸  æœªè¿æ¥ NATS - å•èŠ‚ç‚¹æ¨¡å¼è¿è¡Œ");
    }

    // åˆå§‹åŒ–åŒæ­¥ç®¡ç†å™¨
    let node_id = scru128::new_string();
    let sync_manager = SyncManager::new(
        node_id.clone(),
        Arc::new(storage.clone()),
        notifier.clone().map(Arc::new),
    );
    info!("åŒæ­¥ç®¡ç†å™¨å·²åˆå§‹åŒ–: node_id={}", node_id);

    // åˆå§‹åŒ–ç‰ˆæœ¬ç®¡ç†å™¨
    let version_config = VersionConfig::default();
    let version_manager = VersionManager::new(
        Arc::new(storage.clone()),
        version_config,
        &config.storage.root_path.to_string_lossy(),
    );
    version_manager.init().await?;
    info!("ç‰ˆæœ¬ç®¡ç†å™¨å·²åˆå§‹åŒ–");

    // åˆå§‹åŒ–æœç´¢å¼•æ“
    let index_path = std::path::PathBuf::from(&config.storage.root_path).join("index");
    let search_engine = Arc::new(crate::search::SearchEngine::new(index_path)?);
    info!("æœç´¢å¼•æ“å·²åˆå§‹åŒ–");

    // è®¡ç®—å¯¹å¤– HTTP åŸºå€ï¼ˆä¼˜å…ˆ ADVERTISE_HOSTï¼Œå¦åˆ™å®¹å™¨ HOSTNAMEï¼‰ï¼Œç”¨äºäº‹ä»¶æºå¸¦æºåœ°å€
    let advertise_host = std::env::var("ADVERTISE_HOST")
        .ok()
        .or_else(|| std::env::var("HOSTNAME").ok())
        .unwrap_or_else(|| config.server.host.clone());
    let source_http_addr = format!("http://{}:{}", advertise_host, config.server.http_port);

    // åˆ›å»ºé€€å‡ºä¿¡å·é€šé“
    let (shutdown_tx, shutdown_rx) = tokio::sync::watch::channel(false);

    // æ”¶é›†æ‰€æœ‰æœåŠ¡å™¨çš„ä»»åŠ¡å¥æŸ„ï¼Œç”¨äºé€€å‡ºæ—¶ä¸­æ­¢
    let mut server_handles = Vec::new();

    // å¯åŠ¨äº‹ä»¶ç›‘å¬å™¨ï¼ˆä»…åœ¨ NATS è¿æ¥æˆåŠŸæ—¶ï¼‰
    if let Some(ref nats_notifier) = notifier {
        let event_listener = EventListener::new(
            sync_manager.clone(),
            nats_notifier.get_client(),
            config.nats.topic_prefix.clone(),
            storage.clone(),
            config.storage.chunk_size,
            config.sync.http_connect_timeout,
            config.sync.http_request_timeout,
            config.sync.fetch_max_retries,
            config.sync.fetch_base_backoff,
            config.sync.fetch_max_backoff,
        );
        let mut shutdown_rx_clone = shutdown_rx.clone();
        tokio::spawn(async move {
            tokio::select! {
                result = event_listener.start() => {
                    if let Err(e) = result {
                        error!("äº‹ä»¶ç›‘å¬å™¨é”™è¯¯: {}", e);
                    }
                }
                _ = shutdown_rx_clone.changed() => {
                    info!("äº‹ä»¶ç›‘å¬å™¨æ”¶åˆ°é€€å‡ºä¿¡å·");
                }
            }
        });
        info!("äº‹ä»¶ç›‘å¬å™¨å·²å¯åŠ¨");
    } else {
        info!("è·³è¿‡äº‹ä»¶ç›‘å¬å™¨ï¼ˆå•èŠ‚ç‚¹æ¨¡å¼ï¼‰");
    }

    // å¯åŠ¨ HTTP æœåŠ¡å™¨ï¼ˆä½¿ç”¨ Silent æ¡†æ¶ï¼‰
    let http_addr = format!("{}:{}", config.server.host, config.server.http_port);
    let http_addr_clone = http_addr.clone();
    let storage_clone = storage.clone();
    let notifier_clone = notifier.clone();
    let sync_clone = sync_manager.clone();
    let version_clone = version_manager.clone();
    let search_clone = search_engine.clone();
    let config_clone = config.clone();
    // source_http_addr å·²ç”¨äº HTTP/WebDAV/S3 ä¸‰å¤„ï¼Œä¸å†å•ç‹¬å¤åˆ¶

    let http_handle = tokio::spawn(async move {
        if let Err(e) = http::start_http_server(
            &http_addr_clone,
            storage_clone,
            notifier_clone,
            sync_clone,
            version_clone,
            search_clone,
            config_clone,
        )
        .await
        {
            error!("HTTP æœåŠ¡å™¨é”™è¯¯: {}", e);
        }
    });
    server_handles.push(http_handle);

    // å¯åŠ¨å®šæœŸå·¡æ£€è¡¥æ‹‰ä»»åŠ¡ï¼ˆä»…åœ¨å¤šèŠ‚ç‚¹/NATSå¼€å¯æ—¶éœ€è¦ï¼‰
    if notifier.is_some() {
        let storage_reconcile = storage.clone();
        let sync_reconcile = sync_manager.clone();
        let sync_cfg_reconcile = config.sync.clone();
        let mut shutdown_rx_reconcile = shutdown_rx.clone();
        tokio::spawn(async move {
            use tokio::time::{Duration, sleep};
            loop {
                tokio::select! {
                    _ = sleep(Duration::from_secs(30)) => {
                        let states = sync_reconcile.get_all_sync_states().await;
                        for st in states {
                            if st.is_deleted() { continue; }
                            if let Some(meta) = st.get_metadata().cloned() {
                                let need_fetch = match storage_reconcile.get_metadata(&st.file_id).await {
                                    Ok(local) => local.hash != meta.hash || local.size != meta.size,
                                    Err(_) => true,
                                };
                                if need_fetch && let Some(src) = sync_reconcile.get_last_source(&st.file_id).await {
                                    let client = reqwest::Client::builder()
                                        .connect_timeout(Duration::from_secs(sync_cfg_reconcile.http_connect_timeout))
                                        .timeout(Duration::from_secs(sync_cfg_reconcile.http_request_timeout))
                                        .build()
                                        .unwrap_or_else(|_| reqwest::Client::new());
                                    let url = format!("{}/api/files/{}", src.trim_end_matches('/'), st.file_id);
                                    let mut last_err: Option<String> = None;
                                    let mut ok = false;
                                    for attempt in 0..=sync_cfg_reconcile.fetch_max_retries {
                                        match client.get(&url).send().await {
                                            Ok(resp) if resp.status().is_success() => {
                                                if let Ok(bytes) = resp.bytes().await {
                                                    let actual = format!("{:x}", sha2::Sha256::digest(&bytes));
                                                    if actual != meta.hash {
                                                        last_err = Some(format!("å“ˆå¸Œä¸ä¸€è‡´ expected={} actual={}", meta.hash, actual));
                                                    } else if let Err(e) = storage_reconcile.save_file(&st.file_id, &bytes).await {
                                                        last_err = Some(format!("ä¿å­˜å¤±è´¥: {}", e));
                                                    } else {
                                                        info!("ğŸ“¥ è¡¥æ‹‰å·²å®Œæˆ: {}", st.file_id);
                                                        ok = true;
                                                        break;
                                                    }
                                                }
                                            }
                                            Ok(resp) => { last_err = Some(format!("HTTP {}", resp.status())); }
                                            Err(e) => { last_err = Some(format!("è¯·æ±‚å¤±è´¥: {}", e)); }
                                        }
                                        if attempt < sync_cfg_reconcile.fetch_max_retries {
                                            let factor = 1u64 << (attempt.min(6));
                                            let mut secs = sync_cfg_reconcile.fetch_base_backoff.saturating_mul(factor);
                                            if secs > sync_cfg_reconcile.fetch_max_backoff { secs = sync_cfg_reconcile.fetch_max_backoff; }
                                            let jitter = rand::random::<f64>() * 0.4 + 0.8;
                                            let dur = Duration::from_secs(((secs as f64) * jitter).round() as u64);
                                            sleep(dur).await;
                                        }
                                    }
                                    if !ok {
                                        warn!("è¡¥æ‹‰å¤±è´¥: {} - {}", st.file_id, last_err.unwrap_or_else(||"unknown".into()));
                                    }
                                }
                            }
                        }
                    }
                    _ = shutdown_rx_reconcile.changed() => {
                        info!("å·¡æ£€è¡¥æ‹‰ä»»åŠ¡æ”¶åˆ°é€€å‡ºä¿¡å·");
                        break;
                    }
                }
            }
        });
    } else {
        debug!("è·³è¿‡å·¡æ£€è¡¥æ‹‰ä»»åŠ¡ï¼ˆå•èŠ‚ç‚¹æˆ– NATS æœªå¯ç”¨ï¼‰");
    }

    // å¯åŠ¨ gRPC æœåŠ¡å™¨
    let grpc_addr: SocketAddr = format!("{}:{}", config.server.host, config.server.grpc_port)
        .parse()
        .expect("æ— æ•ˆçš„ gRPC åœ°å€");

    let storage_clone = storage.clone();
    let notifier_clone = notifier.clone();
    let source_http_addr_clone = source_http_addr.clone();

    let sync_for_grpc = sync_manager.clone();
    let node_cfg = config.node.clone();
    let sync_cfg = config.sync.clone();
    let grpc_handle = tokio::spawn(async move {
        if let Err(e) = start_grpc_server(
            grpc_addr,
            storage_clone,
            notifier_clone,
            source_http_addr_clone,
            sync_for_grpc,
            node_cfg,
            sync_cfg,
        )
        .await
        {
            error!("gRPC æœåŠ¡å™¨é”™è¯¯: {}", e);
        }
    });
    server_handles.push(grpc_handle);

    // å¯åŠ¨ WebDAV æœåŠ¡å™¨
    let webdav_addr = format!("{}:{}", config.server.host, config.server.webdav_port);
    let webdav_addr_clone = webdav_addr.clone();
    let storage_webdav = storage.clone();
    let notifier_webdav = notifier.clone();
    let sync_webdav = sync_manager.clone();
    let version_webdav = version_manager.clone();

    let webdav_handle = tokio::spawn(async move {
        let webdav_base = format!(
            "http://{}:{}",
            advertise_host,
            // ä»ç›‘å¬åœ°å€ä¸­æå–ç«¯å£ä»¥ç¡®ä¿ä¸€è‡´
            webdav_addr_clone
                .rsplit(':')
                .next()
                .unwrap_or(&config.server.webdav_port.to_string())
        );
        if let Err(e) = start_webdav_server(
            &webdav_addr_clone,
            storage_webdav,
            notifier_webdav,
            sync_webdav,
            webdav_base,
            version_webdav,
        )
        .await
        {
            error!("WebDAV æœåŠ¡å™¨é”™è¯¯: {}", e);
        }
    });
    server_handles.push(webdav_handle);

    // åˆå§‹åŒ– S3 ç‰ˆæœ¬æ§åˆ¶ç®¡ç†å™¨
    let s3_versioning_manager = Arc::new(s3::VersioningManager::new());
    info!("S3 ç‰ˆæœ¬æ§åˆ¶ç®¡ç†å™¨å·²åˆå§‹åŒ–");

    // å¯åŠ¨ S3 æœåŠ¡å™¨
    let s3_addr = format!("{}:{}", config.server.host, config.server.s3_port);
    let s3_addr_clone = s3_addr.clone();
    let storage_s3 = storage.clone();
    let notifier_s3 = notifier.clone();
    let s3_config = config.s3.clone();
    let source_http_addr_for_s3 = source_http_addr.clone();
    let s3_versioning_clone = s3_versioning_manager.clone();
    let version_s3 = version_manager.clone();

    let s3_handle = tokio::spawn(async move {
        if let Err(e) = start_s3_server(
            &s3_addr_clone,
            storage_s3,
            notifier_s3,
            s3_config,
            source_http_addr_for_s3,
            s3_versioning_clone,
            version_s3,
        )
        .await
        {
            error!("S3 æœåŠ¡å™¨é”™è¯¯: {}", e);
        }
    });
    server_handles.push(s3_handle);

    // å¯åŠ¨ QUIC æœåŠ¡å™¨
    let quic_addr: SocketAddr = format!("{}:{}", config.server.host, config.server.quic_port)
        .parse()
        .expect("æ— æ•ˆçš„ QUIC åœ°å€");

    let storage_quic = storage.clone();
    let notifier_quic = notifier.clone();
    let quic_handle = tokio::spawn(async move {
        let mut quic_server = transfer::QuicTransferServer::new(storage_quic, notifier_quic);
        if let Err(e) = quic_server.start(quic_addr).await {
            error!("QUIC æœåŠ¡å™¨é”™è¯¯: {}", e);
        }
    });
    server_handles.push(quic_handle);

    info!("æ‰€æœ‰æœåŠ¡å·²å¯åŠ¨");
    info!("  HTTP:    http://{}", http_addr);
    info!("  gRPC:    {}", grpc_addr);
    info!("  WebDAV:  http://{}", webdav_addr);
    info!("  S3:      http://{}", s3_addr);
    info!("  QUIC:    {}", quic_addr);

    // ä¿æŒè¿è¡Œï¼Œä¼˜é›…å¤„ç† SIGINT/SIGTERMï¼ˆåŒæ—¶ç›‘å¬ä¸¤ç§ä¿¡å·ï¼‰
    #[cfg(unix)]
    {
        use tokio::signal::unix::{SignalKind, signal};
        let mut sigterm = signal(SignalKind::terminate()).expect("æ³¨å†Œ SIGTERM å¤±è´¥");
        let mut sigint = signal(SignalKind::interrupt()).expect("æ³¨å†Œ SIGINT å¤±è´¥");

        tokio::select! {
            _ = sigterm.recv() => {
                info!("æ”¶åˆ° SIGTERM ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...");
            }
            _ = sigint.recv() => {
                info!("æ”¶åˆ° SIGINT ä¿¡å· (Ctrl+C)ï¼Œæ­£åœ¨é€€å‡º...");
            }
        }
    }

    #[cfg(not(unix))]
    {
        tokio::signal::ctrl_c().await.expect("ç›‘å¬ Ctrl+C å¤±è´¥");
        info!("æ”¶åˆ°å…³é—­ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...");
    }

    // å‘é€é€€å‡ºä¿¡å·ç»™æ‰€æœ‰åå°ä»»åŠ¡
    let _ = shutdown_tx.send(true);
    info!("å·²é€šçŸ¥æ‰€æœ‰åå°ä»»åŠ¡é€€å‡º");

    // ä¸­æ­¢æ‰€æœ‰æœåŠ¡å™¨ä»»åŠ¡
    for handle in server_handles {
        handle.abort();
    }
    info!("å·²ä¸­æ­¢æ‰€æœ‰æœåŠ¡å™¨ä»»åŠ¡");

    // ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©ä»»åŠ¡æ¸…ç†
    tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
    info!("åº”ç”¨å·²é€€å‡º");

    Ok(())
}

/// å¯åŠ¨ gRPC æœåŠ¡å™¨
async fn start_grpc_server(
    addr: SocketAddr,
    storage: StorageManager,
    notifier: Option<EventNotifier>,
    source_http_addr: String,
    sync_manager: Arc<SyncManager>,
    node_cfg: config::NodeConfig,
    sync_cfg: config::SyncBehaviorConfig,
) -> Result<()> {
    use crate::sync::node::manager::{
        NodeDiscoveryConfig, NodeManager, NodeSyncCoordinator, SyncConfig,
    };
    use crate::sync::node::service::NodeSyncServiceImpl;

    let file_service = FileServiceImpl::new(
        storage.clone(),
        notifier.clone(),
        Some(source_http_addr.clone()),
    );

    // åˆå§‹åŒ–èŠ‚ç‚¹åŒæ­¥æœåŠ¡ï¼ˆNodeSyncServiceï¼‰
    let listen_addr = addr.to_string();
    let node_discovery = NodeDiscoveryConfig {
        node_id: sync_manager.node_id().to_string(),
        listen_addr: listen_addr.clone(),
        seed_nodes: if node_cfg.enable {
            node_cfg.seed_nodes.clone()
        } else {
            Vec::new()
        },
        heartbeat_interval: node_cfg.heartbeat_interval,
        node_timeout: node_cfg.node_timeout,
    };

    let node_manager = NodeManager::new(node_discovery, sync_manager.clone());
    let node_sync = NodeSyncCoordinator::new(
        SyncConfig {
            auto_sync: sync_cfg.auto_sync,
            sync_interval: sync_cfg.sync_interval,
            max_files_per_sync: sync_cfg.max_files_per_sync,
            max_retries: sync_cfg.max_retries,
            fail_queue_max: sync_cfg.fail_queue_max,
            fail_task_ttl_secs: sync_cfg.fail_task_ttl_secs,
        },
        node_manager.clone(),
        sync_manager.clone(),
        Arc::new(storage.clone()),
    );

    // å¯åŠ¨èŠ‚ç‚¹å¿ƒè·³ä¸è‡ªåŠ¨åŒæ­¥ä»»åŠ¡
    if node_cfg.enable {
        let nm_for_heartbeat = node_manager.clone();
        tokio::spawn(async move { nm_for_heartbeat.start_heartbeat_check().await });
        // å¯åŠ¨å‘å¤–å‘é€å¿ƒè·³ä»»åŠ¡ï¼Œé™ä½èŠ‚ç‚¹ç¦»çº¿è¯¯åˆ¤æ¦‚ç‡
        let nm_for_outbound = node_manager.clone();
        tokio::spawn(async move { nm_for_outbound.start_outbound_heartbeat().await });
    }

    if node_cfg.enable && sync_cfg.auto_sync {
        let nsc_for_auto = node_sync.clone();
        tokio::spawn(async move { nsc_for_auto.start_auto_sync().await });
    }

    // å¯é€‰ï¼šè¿æ¥åˆ°ç§å­èŠ‚ç‚¹ï¼ˆé»˜è®¤ç©ºåˆ—è¡¨ï¼‰
    if node_cfg.enable
        && !node_cfg.seed_nodes.is_empty()
        && let Err(e) = node_manager.connect_to_seeds().await
    {
        tracing::warn!("è¿æ¥ç§å­èŠ‚ç‚¹å¤±è´¥: {}", e);
    }

    let node_service = NodeSyncServiceImpl::new(
        node_manager,
        node_sync,
        sync_manager,
        Arc::new(storage.clone()),
    );

    info!("gRPC æœåŠ¡å™¨å¯åŠ¨: {}", addr);

    TonicServer::builder()
        .add_service(file_service.into_server())
        .add_service(node_service.into_server())
        .serve(addr)
        .await
        .map_err(|e| error::NasError::Storage(format!("gRPC æœåŠ¡å™¨é”™è¯¯: {}", e)))?;

    Ok(())
}

/// å¯åŠ¨ WebDAV æœåŠ¡å™¨
async fn start_webdav_server(
    addr: &str,
    storage: StorageManager,
    notifier: Option<EventNotifier>,
    sync_manager: Arc<SyncManager>,
    source_http_addr: String,
    version_manager: Arc<VersionManager>,
) -> Result<()> {
    let storage = Arc::new(storage);
    let notifier = notifier.map(Arc::new);

    let route = webdav::create_webdav_routes(
        storage,
        notifier,
        sync_manager,
        source_http_addr,
        version_manager,
    );

    info!("WebDAV æœåŠ¡å™¨å¯åŠ¨: {}", addr);
    // å®é™…æŒ‚è½½åœ¨æ ¹è·¯å¾„ï¼Œé¿å…è¯¯å¯¼ä¸º /webdav
    info!("  - WebDAV: http://{}/", addr);

    Server::new()
        .bind(addr.parse().expect("æ— æ•ˆçš„ WebDAV åœ°å€"))
        .serve(route)
        .await;

    Ok(())
}

/// å¯åŠ¨ S3 æœåŠ¡å™¨
async fn start_s3_server(
    addr: &str,
    storage: StorageManager,
    notifier: Option<EventNotifier>,
    s3_config: config::S3Config,
    source_http_addr: String,
    versioning_manager: Arc<s3::VersioningManager>,
    version_manager: Arc<VersionManager>,
) -> Result<()> {
    let storage = Arc::new(storage);
    let notifier = notifier.map(Arc::new);

    // é…ç½®S3è®¤è¯
    let auth = if s3_config.enable_auth {
        Some(s3::S3Auth::new(s3_config.access_key, s3_config.secret_key))
    } else {
        None
    };

    let route = s3::create_s3_routes(
        storage,
        notifier,
        auth,
        source_http_addr.clone(),
        versioning_manager,
        version_manager,
    );

    info!("S3 æœåŠ¡å™¨å¯åŠ¨: {}", addr);
    info!("  - S3 API: http://{}/", addr);

    Server::new()
        .bind(addr.parse().expect("æ— æ•ˆçš„ S3 åœ°å€"))
        .serve(route)
        .await;

    Ok(())
}
